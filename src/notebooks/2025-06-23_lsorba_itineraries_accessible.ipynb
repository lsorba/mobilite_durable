{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc994db2badef6e",
   "metadata": {},
   "source": [
    "üöå Projet MDM - Mobilit√© Durable en Montagne ‚õ∞Ô∏è\n",
    "\n",
    "*Author : Laurent Sorba*\n",
    "\n",
    "*Date : 23/06/2025*\n",
    "\n",
    "**Description :**\n",
    "\n",
    "This Jupyter Notebook analyses the accessibility of the itineraries by measuring proximity to public transport stops, using pandas/geopandas to parse waypoints from the C2C CSV export for Is√®re `List_iti_D4G_isre.csv` and extract bus stop locations from a PostgreSQL SQL C2C dump  `UTF-8dump-c2corg-202505050900.sql.zip`. It performs spatial analysis to count itineraries within 0.5km‚Äì5km zones around bus stops using the EPSG:3857 coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import binascii\n",
    "import re\n",
    "import struct\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd72dc5f48efb07",
   "metadata": {},
   "source": "## 1. Load and Parse Itinerary Data from CSV"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7947e00f32a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "csv_path = \"../data/C2C/Liste_iti_D4G_isere.csv\"\n",
    "df = pd.read_csv(csv_path, on_bad_lines=\"skip\", low_memory=False)\n",
    "\n",
    "# Display sample data\n",
    "print(\"First 2 rows of original CSV:\")\n",
    "print(df.head(2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e77f011e471bf",
   "metadata": {},
   "source": "## 2. Extract Waypoints from CSV"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584de18e6753697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified pattern that focuses only on [X, Y] coordinates\n",
    "coord_pattern = re.compile(r\"\\s*([+-]?\\d+[\\.\\d]*)\\s*,\\s*([+-]?\\d+[\\.\\d]*)\\s*\")\n",
    "\n",
    "# List to store parsed waypoints\n",
    "waypoints = []\n",
    "\n",
    "# Identify waypoint columns (columns 9 onward)\n",
    "waypoint_cols = df.columns[9:]\n",
    "\n",
    "# Parse waypoints\n",
    "for idx, row in df.iterrows():\n",
    "    itinerary_id = row[\"Id itin√©raire\"]\n",
    "\n",
    "    for col in waypoint_cols:\n",
    "        cell = str(row[col])\n",
    "        if not cell or cell == \"nan\":\n",
    "            continue\n",
    "\n",
    "        match = coord_pattern.search(cell)\n",
    "        if match:\n",
    "            try:\n",
    "                x = float(match.group(1))\n",
    "                y = float(match.group(2))\n",
    "\n",
    "                waypoints.append({\"itinerary_id\": itinerary_id, \"geometry\": Point(x, y)})\n",
    "\n",
    "            except (ValueError, TypeError):\n",
    "                continue  # Skip invalid coordinates\n",
    "\n",
    "# Create GeoDataFrame\n",
    "if waypoints:\n",
    "    wp_gdf = gpd.GeoDataFrame(pd.DataFrame(waypoints), geometry=\"geometry\", crs=\"EPSG:3857\")\n",
    "    print(f\"\\n‚úÖ Successfully parsed {len(wp_gdf)} waypoints\")\n",
    "else:\n",
    "    print(\"üö® No coordinates found. Check if any cell contains [X, Y] format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f93c5b80bc1ca",
   "metadata": {},
   "source": "## 3. Load Bus Stop Data from PostgreSQL"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab5f6de35b96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "def parse_sql_dump(sql_file):\n",
    "    # Pattern to match INSERT statements\n",
    "    insert_pattern = re.compile(r\"INSERT INTO guidebook\\.stopareas VALUES (.*?);\", re.DOTALL)\n",
    "\n",
    "    # List to store parsed stop areas\n",
    "    stopareas = []\n",
    "\n",
    "    with open(sql_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Process each INSERT statement\n",
    "    for match in insert_pattern.finditer(content):\n",
    "        values_str = match.group(1)\n",
    "\n",
    "        # Split values preserving quoted strings (handling escaped quotes)\n",
    "        values = []\n",
    "        current = \"\"\n",
    "        in_quote = False\n",
    "        escape_next = False\n",
    "\n",
    "        for char in values_str:\n",
    "            if escape_next:\n",
    "                current += char\n",
    "                escape_next = False\n",
    "                continue\n",
    "\n",
    "            if char == \"\\\\\":\n",
    "                escape_next = True\n",
    "                continue\n",
    "\n",
    "            if char == \"'\":\n",
    "                in_quote = not in_quote\n",
    "                continue\n",
    "\n",
    "            if char == \",\" and not in_quote:\n",
    "                values.append(current.strip())\n",
    "                current = \"\"\n",
    "                continue\n",
    "\n",
    "            current += char\n",
    "\n",
    "        if current.strip():\n",
    "            values.append(current.strip())\n",
    "\n",
    "        # Ensure we have enough values (at least 6)\n",
    "        if len(values) < 6:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Extract basic fields\n",
    "            stoparea_id = int(values[0].strip(\"(\"))\n",
    "            navitia_id = values[1].strip(\"'\")\n",
    "            stoparea_name = values[2].strip(\"'\")\n",
    "            line = values[3].strip(\"'\")\n",
    "            operator = values[4].strip(\"'\")\n",
    "            ewkb_hex = values[5].strip(\"')\")\n",
    "\n",
    "            # Skip if geometry is NULL\n",
    "            if ewkb_hex.upper() == \"NULL\":\n",
    "                continue\n",
    "\n",
    "            # Convert hex to binary\n",
    "            try:\n",
    "                ewkb_bytes = binascii.unhexlify(ewkb_hex)\n",
    "            except binascii.Error:\n",
    "                continue\n",
    "\n",
    "            # Check if we have enough data\n",
    "            if len(ewkb_bytes) < 17:  # Minimum for point without SRID\n",
    "                continue\n",
    "\n",
    "            # Read byte order (1 = little, 0 = big)\n",
    "            byte_order = ewkb_bytes[0]\n",
    "            is_little_endian = byte_order == 1\n",
    "\n",
    "            # Read geometry type (4 bytes)\n",
    "            geom_type_bytes = ewkb_bytes[1:5]\n",
    "\n",
    "            # Extract geometry type (first 4 bits) and flags\n",
    "            if is_little_endian:\n",
    "                geom_type = struct.unpack(\"<I\", geom_type_bytes)[0]\n",
    "            else:\n",
    "                geom_type = struct.unpack(\">I\", geom_type_bytes)[0]\n",
    "\n",
    "            # Check if this is a point (type = 1) - ignore flags\n",
    "            if (geom_type & 0x07) != 1:  # Use bitmask to ignore SRID flag and others\n",
    "                continue\n",
    "\n",
    "            # Read SRID if present (bit 3 of geom_type is set)\n",
    "            offset = 5\n",
    "            srid = None\n",
    "            if geom_type & 0x20000000:  # Check if SRID flag is set\n",
    "                if len(ewkb_bytes) < 9:\n",
    "                    continue\n",
    "                if is_little_endian:\n",
    "                    srid = struct.unpack(\"<I\", ewkb_bytes[5:9])[0]\n",
    "                else:\n",
    "                    srid = struct.unpack(\">I\", ewkb_bytes[5:9])[0]\n",
    "                offset = 9\n",
    "\n",
    "            # Read coordinates\n",
    "            if len(ewkb_bytes) < offset + 16:  # 8 bytes for x, 8 for y\n",
    "                continue\n",
    "\n",
    "            # Extract X and Y coordinates\n",
    "            if is_little_endian:\n",
    "                x = struct.unpack(\"<d\", ewkb_bytes[offset : offset + 8])[0]\n",
    "                y = struct.unpack(\"<d\", ewkb_bytes[offset + 8 : offset + 16])[0]\n",
    "            else:\n",
    "                x = struct.unpack(\">d\", ewkb_bytes[offset : offset + 8])[0]\n",
    "                y = struct.unpack(\">d\", ewkb_bytes[offset + 8 : offset + 16])[0]\n",
    "\n",
    "            # Add to list\n",
    "            stopareas.append(\n",
    "                {\n",
    "                    \"stoparea_id\": stoparea_id,\n",
    "                    \"navitia_id\": navitia_id,\n",
    "                    \"stoparea_name\": stoparea_name,\n",
    "                    \"line\": line,\n",
    "                    \"operator\": operator,\n",
    "                    \"srid\": srid,\n",
    "                    \"geometry\": Point(x, y),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception:\n",
    "            # Skip problematic rows\n",
    "            continue\n",
    "\n",
    "    # Create GeoDataFrame\n",
    "    if stopareas:\n",
    "        gdf = gpd.GeoDataFrame(stopareas, geometry=\"geometry\", crs=\"EPSG:3857\")\n",
    "        return gdf\n",
    "    else:\n",
    "        return gpd.GeoDataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a96d6a41ad6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "# Load bus stops from SQL dump\n",
    "zip_path = \"../data/C2C/UTF-8dump-c2corg-202505050900.sql.zip\"\n",
    "sql_filename_inside_zip = \"dump-c2corg-202505050900.sql\"\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            # Extract SQL file to temporary directory\n",
    "            zip_ref.extract(sql_filename_inside_zip, tmp_dir)\n",
    "            sql_file_path = os.path.join(tmp_dir, sql_filename_inside_zip)\n",
    "\n",
    "            stops_gdf = parse_sql_dump(sql_file_path)\n",
    "            print(f\"Loaded {len(stops_gdf)} bus stops from SQL dump\")\n",
    "\n",
    "            print(\"First 2 bus stops:\")\n",
    "            print(stops_gdf.head(2).T)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: ZIP file '{zip_path}' not found.\")\n",
    "except KeyError:\n",
    "    print(f\"Error: '{sql_filename_inside_zip}' not found in the ZIP archive.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a958bb8e495aae",
   "metadata": {},
   "source": "## 4. Spatial Analysis: Buffer Zones"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb0b5aede75fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distances to test\n",
    "distances = [500, 1000, 2000, 3000, 4000, 5000, 6000]  # in meters\n",
    "results = {}\n",
    "\n",
    "# Total itineraries in dataset\n",
    "total_itineraries = df[\"Id itin√©raire\"].nunique()\n",
    "\n",
    "# Analyze for each distance\n",
    "for distance in distances:\n",
    "    # Find waypoints within distance of any bus stop\n",
    "    nearby = gpd.sjoin_nearest(wp_gdf, stops_gdf, how=\"left\", max_distance=distance)\n",
    "\n",
    "    # Get unique itineraries with at least one waypoint within distance\n",
    "    accessible_ids = nearby[nearby[\"index_right\"].notna()][\"itinerary_id\"].unique()\n",
    "    count = len(accessible_ids)\n",
    "\n",
    "    # Store results\n",
    "    results[distance] = {\"count\": count, \"percentage\": (count / total_itineraries) * 100}\n",
    "\n",
    "    print(\n",
    "        f\"\\nWithin {distance}m: {count} itineraries ({results[distance]['percentage']:.1f}% of total)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc86d4aa6e2aed9",
   "metadata": {},
   "source": "## 5. Visualize Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23eefcee77e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"distance\": d, \"count\": r[\"count\"], \"percentage\": r[\"percentage\"]}\n",
    "        for d, r in results.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot counts\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "results_df.set_index(\"distance\")[\"count\"].plot.bar()\n",
    "plt.title(\"Accessible Itineraries by Distance\")\n",
    "plt.xlabel(\"Distance (meters)\")\n",
    "plt.ylabel(\"Number of Itineraries\")\n",
    "\n",
    "# Plot percentages\n",
    "plt.subplot(1, 2, 2)\n",
    "results_df.set_index(\"distance\")[\"percentage\"].plot.bar()\n",
    "plt.title(\"Percentage of Accessible Itineraries\")\n",
    "plt.xlabel(\"Distance (meters)\")\n",
    "plt.ylabel(\"Percentage of Total Itineraries\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c211f0e31dd64e",
   "metadata": {},
   "source": "## 6. Export Results (Optional)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b27af398d8e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export detailed results to CSV\n",
    "results_df.to_csv(\"accessibility_results.csv\", index=False)\n",
    "print(\"Results saved to 'accessibility_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
